总览
========

Redis Cluster的动机和设计目标已经在
Redis Cluster的第一个设计文档。本文档仅是为了
提供一种完全替代的方法来探索更多的想法。

在本文档中，探讨的替代方案是一个集群，其中通信是
直接从客户端执行到目标节点，没有中间层。

中间层可以以代理的形式使用，以提供
与无法直接使用群集协议的客户端具有相同的功能。
因此，在第一阶段，客户端可以使用代理来实现哈希环，但是
稍后，此客户端可以切换到本机实现，
Redis项目将提供的规范。

在这种新设计中，容错通过每次复制M-1次来实现
数据节点，而不是在节点之间存储M次相同的密钥。

从CAP的角度来看，我们最大的牺牲是“ P”，即
抗分区性。只有M-1个节点仍可以关闭群集
发挥作用。同样，在可能的情况下，为“ L”牺牲了“ A”，
是，延迟。不是真正在CAP方程中，而是一个非常重要的参数。

网络布局
==============

在这种替代设计中，网络布局很简单，因为只有
客户直接与N个数据节点对话。因此我们可以想象有：

-K Redis客户端，直接与数据节点通信。
-N个Redis数据节点，即普通Redis实例。

数据节点重复M-1次（因此，总共有M个副本用于
每个节点）。如果M为1，则系统不是容错的。如果M为2
数据节点可以脱机而不会影响操作。依此类推。

哈希槽
==========

密钥空间分为1024个插槽。

给定一个密钥，则将SHA1函数应用于该密钥。
SHA1摘要的前10个字节被解释为无符号整数
从0到1023。这是密钥的哈希槽。

数据节点
==========

数据节点是正常的Redis实例，但还有一些其他命令
提供。

哈希添加...哈希槽列表...
HASHRING DEL ...哈希槽列表...
哈希重排插槽
HASHRING SLOTS =>返回已配置插槽的列表
HSAHRING KEYS ...哈希槽列表...

默认情况下，Redis实例配置为接受关于所有实例的操作
哈希槽。使用此命令可以配置Redis实例
只接受键空间的一个子集。

如果针对密钥散列到不是
配置为被接受，Redis实例将回复：

  “ -ERR错误的哈希槽”

有关HASHRING命令和子命令的更多详细信息将在以后显示
在本文档中。

另外，添加了其他三个命令：

DUMP键
RESTORE键<转储数据>
MIGRATE密钥主机端口

DUMP用于输出密钥处存储的数据的非常紧凑的二进制表示形式。

RESTORE从DUMP产生的输出开始重新创建一个值（将其存储在键中）。

MIGRATE就像服务器端DUMP + RESTORE命令一样。此基本命令将一个键从连接的实例移至另一实例，并返回操作的状态码（+ OK或错误）。

本草稿中描述的协议仅使用MIGRATE命令，但是当连接到另一台服务器时，该协议将在内部使用RESTORE，并且提供DUMP用于对称。

查询集群
====================

1）读取集群配置
-----------------------------

要求集群的客户端加载集群配置
进入记忆。群集配置是以下信息的总和：

-群集中的数据节点数，例如10
-哈希槽和节点之间的映射，因此对于实例：
  哈希槽1->节点0
  哈希插槽2->节点5
  哈希槽3->节点3
  ...等等
-节点及其副本的物理地址。
  节点0地址-> 192.168.1.100
  节点0副本-> 192.168.1.101，192.168.1.105
-配置版本：整个配置的SHA1

配置存储在集群的每个数据节点中。

第一步，需要在内存中没有配置的客户端执行以下操作：
阅读配置。为此，客户端需要具有IP列表
群集中具有高概率数据节点的节点。

客户端将尝试从所有这些节点获取配置。如果找不到节点
响应时，将错误报告给用户。

2）缓存和刷新配置
-------------------------------------------

允许节点将配置缓存在内存中或以其他方式缓存
（例如，将配置存储到文件中），但是每个客户端都是
需要检查配置是否每10秒钟最多更改一次，询问
通过一次GET调用获取配置版本密钥，并检查是否
配置版本与内存中加载的版本匹配。

另外，每当节点出现时，客户端都需要刷新配置
回复：

  “ -ERR错误的哈希槽”

因为这意味着哈希槽以某种方式被重新分配。

从理论上讲，不需要每10秒检查一次配置，但是
防止现实世界中发生的错误和故障的良好保护
环境。作为时间不多的GET操作，执行起来也非常便宜
时间不会对整体绩效产生影响。

3）阅读查询
-------------

为了执行读取查询，客户端从命令中散列key参数
（在Redis Cluster的初始版本中，只有单键命令是
允许）。使用内存中配置，它将哈希键映射到
节点ID。

如果将客户端配置为支持写后读取一致性，则
查询该哈希槽的“主”节点。

否则，客户端从主服务器和副本服务器中选择一个随机节点
可用。

4）写查询
--------------

写查询与读查询完全一样，区别在于
写操作始终针对主节点，而不是副本。

创建集群
==================

为了创建一个新集群，redis-cluster命令行实用程序是
用过的。它获取可用节点和副本的列表，以便编写
所有节点的初始配置。

此时，群集可供客户端使用。

将节点添加到集群
==========================

命令行实用程序redis-cluster用于将节点添加到
簇：

1）集群配置已加载。
2）相当数量的哈希槽分配给了新数据节点。
3）移动到新节点的哈希插槽在旧标记为“ REHASHING”
   节点，使用HASHRING命令：

    散列设定1 192.168.1.103 6380

上面的命令将哈希槽“ 1”设置为重新哈希状态，
“转发地址”到192.168.1.103:6380。结果，如果此节点收到
有关到哈希槽1的密钥哈希的查询，该查询在*中不存在*
当前数据集，它回复：

    “ -MIGRATED 192.168.1.103:6380”

然后，客户端可以针对新节点重新发出查询。

而是即使哈希槽标记为重新哈希，但请求的密钥
仍然存在，查询已处理。这允许非阻塞
重新整理。

请注意，Redis不会使用额外的内存来提供这样的功能。
特征。

4）当哈希槽标记为“ REHASHING”时，redis-cluster询问该节点
匹配指定哈希槽的所有键的列表。然后所有的键
使用MIGRATE命令将其移动到新节点。
5）迁移所有密钥后，哈希槽将从旧的删除
使用“ HASHRING DEL 1”进行节点配置。且配置已更新。

使用此算法，所有哈希槽都一个接一个地迁移到新节点。在实际实施中，开始迁移之前
redis-cluster实用程序应将日志写入配置，以便
如果发生崩溃或任何其他问题，该实用程序可以从
它离开了吗？

容错能力
===============

达到容错能力，复制每个数据节点M-1次，因此我们
有一个主副本和M-1个副本，总共M个节点持有相同的副本
哈希槽。在不影响群集的情况下，最多可以关闭M-1个节点。

关于容错的棘手部分是检测节点何时发生故障并
向其他所有客户端发出信号。

当主节点永久性故障时，升级第一个从节点
简单：
1）在某个时候，客户端会注意到访问给定节点存在问题。它将尝试刷新配置，但会注意到该配置已经是最新的。
2）为了确保问题不在于客户端连接本身，它还将尝试到达其他节点。如果似乎有M-1个以上的节点出现故障，则可能是客户端网络问题，或者是由于太多的节点都已发生故障而无法修复群集。因此，不会采取任何措施，但是会报告一个错误。
3）取而代之的是，如果看起来只有1个或最大M-1个节点出现故障，则客户端会将从属升级为主机，并将新配置写入所有数据节点。

所有其他客户端将看到数据节点不起作用，并且第一步将尝试刷新配置。他们将成功刷新配置，并且群集将再次运行。

每次升级从属服务器时，该信息都会写入所有数据节点中实际上是Redis列表的日志中，以便系统管理工具可以检测到发生了什么情况，以便向管理员发送通知。

间歇性问题
---------------------

在上述情况下，主服务器永久性故障。现在代替
让我们考虑一下网络电缆运行不正常的情况，这样一个节点
似乎要几秒钟，几秒钟下来。

发生这种情况时，恢复可能会困难得多，因为客户可能会注意到
问题，并因此将奴隶提升为主人，但随后主人
将再次启动，其他客户将看不到问题，写信给
老主机最多10秒钟（10秒钟后，所有客户端
需要执行一些GET检查设备的配置版本
群集并根据需要进行更新）。

解决此问题的一种方法是将故障转移机制委托给
故障转移代理。当客户注意到问题时，将不会采取任何主动措施
但只会将问题记录到所有可访问节点的redis列表中，
等待，检查配置更改，然后重试。

故障转移代理会不断监视以下日志：如果某些客户端正在报告
发生故障的节点，它可以采取适当的措施，检查故障是否为
是否永久。如果不是，他可以发送SHUTDOWN命令给失败的人
如果可能的话，掌握。故障转移代理还可以考虑更好的问题
检查失败模式是由所有客户端还是仅由单个客户端发布
一个，并且可以在继续之前检查自己是否存在真正的问题
故障转移。

Redis代理
===========

为了简化到Redis集群版本的切换，并且
因为客户端协议与
通常的Redis客户端lib协议（最小的lib可以小到
100行代码），将提供代理以实现集群协议
作为代理。

每个客户端将与负责使用的redis-proxy节点进行对话
新协议并转发回答复。

从长远来看，目标是将所有主要客户端库都切换到
以本机方式生成新协议。

支持的命令
==================

因为通过这种设计，我们直接与数据节点通信，并且只有一个
每个值的“主”版本（这是从CAP中删除“ P”的最大收获！）
集群版本几乎可以支持所有的redis命令
包括MULTI / EXEC和多键命令，只要所有键都将散列
到相同的哈希槽。为了保证这一点，可以使用关键标签，
当键名称中存在特定模式时，只有该部分是
哈希以获取哈希索引。

随意评论
==============

-尚不清楚如何对从属主机进行原子选举。
-在正常条件下（所有节点都在工作），这种新设计仅仅是
  K个客户端与N个节点通信，没有中间层，没有路由：
  这意味着它可以通过O（1）查找进行水平扩展。
-集群应该可以选择进行手动故障转移
  适用于需要这样做的环境。例如有可能
  在所有节点上设置定期检查，并在需要时切换IP
  或其他不能作为默认配置的高级配置
  过于依赖环境。

关于客户端从站选举的一些想法
===========================================

协作检测故障
-----------------------------------------

为了进行节点故障检测和从站选举
努力，没有任何“控制程序”，从某种意义上讲，这是一点
故障（群集停止时不会停止，但不会出现错误）
更正，而无需运行），可以使用一些相同的共识
算法。

例如，所有节点都可以获取客户端检测到的错误列表。

如果客户端1在访问节点3时检测到某些故障，例如连接
拒绝错误或超时，它将记录LPUSH命令针对
所有其他节点。此“错误消息”将具有时间戳记和节点
ID。就像是：

    LPUSH __cluster__：错误3：1272545939

因此，如果在短时间内多次报告错误，则有时
指出客户可以就是否需要执行
奴隶选举。

原子奴隶选举
---------------------

为了避免在选举奴隶为主时发生种族冲突（即为了
避免某些客户端仍然可以联系该节点中的旧主节点
10秒的时间范围内），执行选举的客户可以写
配置中的一些提示，请相应地更改配置SHA1并
等待10秒钟以上，以确保所有客户端
在进行新访问之前刷新配置。

配置提示可能类似于：

“我们将在几秒钟内切换到一个新的主服务器，即x.y.z.k：port”。

当客户端更新配置并找到这样的标志集时，它开始
持续刷新配置，直到发现更改为止（这将需要
最多10-15秒）。

执行选举的客户将等待那个著名的10秒时间范围
最后将以一种确定的方式更新配置，设置新
奴隶主。此时，所有客户都将获得新的
config是因为它们刷新了，还是因为在下一次查询中它们的配置
已过期，他们将更新配置。

紧急行动